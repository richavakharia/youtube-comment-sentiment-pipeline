{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup"
      ],
      "metadata": {
        "id": "bv8vdOzkjyOw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tNMKF6tlqrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14faf8c-279d-4701-f6b5-23c7330813e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyspark==3.5.1\n"
      ],
      "metadata": {
        "id": "bsZc1Xe3n-92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(os.listdir(\"/content/drive\"))\n",
        "print(os.listdir(\"/content/drive/Shareddrives\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMlQE8fapvLr",
        "outputId": "789f80d5-a409-4299-d981-1e31fde74441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Shareddrives', 'MyDrive', '.shortcut-targets-by-id', '.Trash-0']\n",
            "['25-26 SASE Cabinet Folder']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(os.listdir(\"/content/drive\"))\n",
        "print(os.listdir(\"/content/drive/Shareddrives\"))\n",
        "print(os.listdir(\"/content/drive/MyDrive\"))\n",
        "print(os.listdir(\"/content/drive/MyDrive/CS 131 Term Project\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "SISqe3D7sKL0",
        "outputId": "74c64e64-e2f4-4262-8e97-b0c35992a4aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Shareddrives', 'MyDrive', '.shortcut-targets-by-id', '.Trash-0']\n",
            "['25-26 SASE Cabinet Folder']\n",
            "['Jacob_Atanacio_Resume.pdf', '22-B_Data_Analysis_for_Python', 'Colab Notebooks', 'Data.csv.gsheet', 'Copy of Copy of SCE Interview Practice Problem.gdoc', 'Defense of slavery AMS10.gdoc', 'Atanacio_100W_PresentationScript.gdoc', 'Atanacio_The Role of Data Science in Healthcare.gslides', 'Atanacio_WritingExericise2.gdoc', 'Atanacio_SlaveNarrative_Comparison_Brainstorm.gdoc', 'Atanacio_SlaveNarrative_Comparison.gdoc', 'Underground Railroad.gdoc', 'Atanacio_Artifact_Analysis.gdoc', 'CS100W Critical Analysis.gdoc', 'CS 100W Pursuasive Language Exercise.gdoc', 'Interview Notes.gdoc', 'Unit3_GoldRushInterculturalInteractions.docx', 'Untitled0.ipynb', 'Atanacio_Interview_Assignment.gdoc', 'Atanacio_Public_History_Site.gdoc', 'MT 2 Cheat sheet.gdoc', 'Midterm_2_StudyGuide.docx', 'MT_2_cheat_sheet.pdf', 'Atanacio_Writing_Exercise_3.gdoc', 'Atanacio_Research_Paper .gdoc', 'Atanacio_WritingExercise4.gdoc', 'Atanacio_UndergroundRailroad_ParticipationEvaluation-.docx', 'Final Review .pdf', 'Hands on reviews', 'Copy of data.csv', 'Final Review .gdoc', 'FINAL CS.pdf', 'Atanacio_AMS 10 FInal Essay.gdoc', 'MySJSU_ Unofficial Transcript.pdf', 'Jacob Atanacio_Introduction_CS46B.gslides', 'CS46B-Prereq Form-v6 RC.docx', '119 Assignment 1 S2024 (Electricity).docx', 'SWJacob_Atanacio_Resume.pdf', 'AtanacioAssignment1_PersonalWrkLog.gdoc', 'Federalism Discussion.gdoc', 'lab4.jar', 'Atanacio_Electricity personal work log.gdoc', 'W4W5-IO and Exception 1-Ricky Chan v2.pptx', 'Project proposal.gdoc', 'JacobAtanacio_Resume_MASTER (1).pdf', 'AtanacioENVS_Assignment3.gdoc', 'AMS11 Capstone Proposal.gdoc', 'MajorAdvisingReleaseForm_Oct2023.gdoc', 'AMS 11 Capstone.gslides', 'ENVS Capstone Essay_Atanacio.gdoc', 'presentation notes.gdoc', 'Math167R Cheatsheet.gdoc', 'AMS11 Capstone.gdoc', 'pfp.jpg', 'Marketing Dir. Portfolio', 'Untitled document.gdoc', 'vi_cheat_sheet.pdf', '131cheatsheet.pdf', 'PHIL 133_outline.gdoc', 'Atanacio_Phil_133_Essay1.gdoc', 'CS146_hw2_atanacio.gdoc', 'CS146hw3_atanacio.gdoc', 'CS 131 Midterm 2 CheatSheet    Karmehr Arora.gdoc', 'team 2 sase mentorship.gslides', 'Copy of CS 131 Midterm 2 CheatSheet    Karmehr Arora.gdoc', 'Cs.pdf', 'yt_comments.csv', 'yt_comments (1).gsheet', 'MajorAdvisingReleaseFormFA25.gdoc', 'MajorAdvisingReleaseFormFA25.pdf', 'yt_comments.gsheet', 'lease2526.pdf', 'MIDUS 2', 'Atanacio_Phil_133_Essay2.gdoc']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/CS 131 Term Project'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4081963989.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/Shareddrives\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/CS 131 Term Project\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/CS 131 Term Project'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -y && apt-get install -y openjdk-17-jdk-headless\n"
      ],
      "metadata": {
        "id": "72zCJZfJqZIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35d88d93-c024-4345-fa29-e3b5c6469b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (13.225.47.84)] [Con\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [2 InRelease 30.1 kB/128 kB 24%] [3 InRelease 66.3 kB/129 kB 51%] [Waiting f\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "\r0% [2 InRelease 47.5 kB/128 kB 37%] [3 InRelease 90.9 kB/129 kB 71%] [4 InRelea\r                                                                               \rHit:5 https://cli.github.com/packages stable InRelease\n",
            "\r0% [2 InRelease 47.5 kB/128 kB 37%] [3 InRelease 93.8 kB/129 kB 73%] [4 InRelea\r0% [2 InRelease 47.5 kB/128 kB 37%] [3 InRelease 93.8 kB/129 kB 73%] [Connected\r0% [2 InRelease 67.7 kB/128 kB 53%] [Connected to r2u.stat.illinois.edu (192.17\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connectin\r                                                                               \rGet:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,526 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,856 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,969 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,123 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,289 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,168 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,436 kB]\n",
            "Get:20 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
            "Get:21 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,825 kB]\n",
            "Fetched 37.2 MB in 5s (8,150 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  ca-certificates-java java-common libpcsclite1 openjdk-17-jre-headless\n",
            "Suggested packages:\n",
            "  default-jre pcscd openjdk-17-demo openjdk-17-source libnss-mdns\n",
            "  fonts-dejavu-extra fonts-ipafont-gothic fonts-ipafont-mincho\n",
            "  fonts-wqy-microhei | fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  ca-certificates-java java-common libpcsclite1 openjdk-17-jdk-headless\n",
            "  openjdk-17-jre-headless\n",
            "0 upgraded, 5 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 120 MB of archives.\n",
            "After this operation, 272 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 java-common all 0.72build2 [6,782 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpcsclite1 amd64 1.9.5-3ubuntu1 [19.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jre-headless amd64 17.0.16+8~us1-0ubuntu1~22.04.1 [48.3 MB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ca-certificates-java all 20190909ubuntu1.2 [12.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-17-jdk-headless amd64 17.0.16+8~us1-0ubuntu1~22.04.1 [71.3 MB]\n",
            "Fetched 120 MB in 2s (48.5 MB/s)\n",
            "Selecting previously unselected package java-common.\n",
            "(Reading database ... 125082 files and directories currently installed.)\n",
            "Preparing to unpack .../java-common_0.72build2_all.deb ...\n",
            "Unpacking java-common (0.72build2) ...\n",
            "Selecting previously unselected package libpcsclite1:amd64.\n",
            "Preparing to unpack .../libpcsclite1_1.9.5-3ubuntu1_amd64.deb ...\n",
            "Unpacking libpcsclite1:amd64 (1.9.5-3ubuntu1) ...\n",
            "Selecting previously unselected package openjdk-17-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-17-jre-headless_17.0.16+8~us1-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-17-jre-headless:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "Selecting previously unselected package ca-certificates-java.\n",
            "Preparing to unpack .../ca-certificates-java_20190909ubuntu1.2_all.deb ...\n",
            "Unpacking ca-certificates-java (20190909ubuntu1.2) ...\n",
            "Selecting previously unselected package openjdk-17-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-17-jdk-headless_17.0.16+8~us1-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking openjdk-17-jdk-headless:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "Setting up java-common (0.72build2) ...\n",
            "Setting up libpcsclite1:amd64 (1.9.5-3ubuntu1) ...\n",
            "Setting up openjdk-17-jre-headless:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jpackage to provide /usr/bin/jpackage (jpackage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/lib/jexec to provide /usr/bin/jexec (jexec) in auto mode\n",
            "Setting up ca-certificates-java (20190909ubuntu1.2) ...\n",
            "head: cannot open '/etc/ssl/certs/java/cacerts' for reading: No such file or directory\n",
            "Adding debian:SecureSign_RootCA11.pem\n",
            "Adding debian:USERTrust_RSA_Certification_Authority.pem\n",
            "Adding debian:AffirmTrust_Commercial.pem\n",
            "Adding debian:DigiCert_Global_Root_G3.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority_-_G2.pem\n",
            "Adding debian:certSIGN_Root_CA_G2.pem\n",
            "Adding debian:Starfield_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:SSL.com_EV_Root_Certification_Authority_RSA_R2.pem\n",
            "Adding debian:QuoVadis_Root_CA_3.pem\n",
            "Adding debian:GlobalSign_Root_CA_-_R6.pem\n",
            "Adding debian:D-TRUST_EV_Root_CA_1_2020.pem\n",
            "Adding debian:HARICA_TLS_RSA_Root_CA_2021.pem\n",
            "Adding debian:Trustwave_Global_Certification_Authority.pem\n",
            "Adding debian:QuoVadis_Root_CA_2_G3.pem\n",
            "Adding debian:Comodo_AAA_Services_root.pem\n",
            "Adding debian:Certum_EC-384_CA.pem\n",
            "Adding debian:GlobalSign_ECC_Root_CA_-_R4.pem\n",
            "Adding debian:Hellenic_Academic_and_Research_Institutions_ECC_RootCA_2015.pem\n",
            "Adding debian:GlobalSign_Root_CA.pem\n",
            "Adding debian:HiPKI_Root_CA_-_G1.pem\n",
            "Adding debian:emSign_Root_CA_-_G1.pem\n",
            "Adding debian:SSL.com_Root_Certification_Authority_RSA.pem\n",
            "Adding debian:CFCA_EV_ROOT.pem\n",
            "Adding debian:COMODO_Certification_Authority.pem\n",
            "Adding debian:DigiCert_High_Assurance_EV_Root_CA.pem\n",
            "Adding debian:T-TeleSec_GlobalRoot_Class_3.pem\n",
            "Adding debian:D-TRUST_Root_Class_3_CA_2_2009.pem\n",
            "Adding debian:Autoridad_de_Certificacion_Firmaprofesional_CIF_A62634068.pem\n",
            "Adding debian:Izenpe.com.pem\n",
            "Adding debian:HARICA_TLS_ECC_Root_CA_2021.pem\n",
            "Adding debian:D-TRUST_Root_Class_3_CA_2_EV_2009.pem\n",
            "Adding debian:Security_Communication_RootCA2.pem\n",
            "Adding debian:UCA_Global_G2_Root.pem\n",
            "Adding debian:D-TRUST_BR_Root_CA_1_2020.pem\n",
            "Adding debian:Secure_Global_CA.pem\n",
            "Adding debian:GTS_Root_R3.pem\n",
            "Adding debian:ISRG_Root_X1.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority.pem\n",
            "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2015.pem\n",
            "Adding debian:GlobalSign_Root_E46.pem\n",
            "Adding debian:vTrus_Root_CA.pem\n",
            "Adding debian:TWCA_Root_Certification_Authority.pem\n",
            "Adding debian:AffirmTrust_Premium.pem\n",
            "Adding debian:XRamp_Global_CA_Root.pem\n",
            "Adding debian:Starfield_Class_2_CA.pem\n",
            "Adding debian:Buypass_Class_2_Root_CA.pem\n",
            "Adding debian:Entrust.net_Premium_2048_Secure_Server_CA.pem\n",
            "Adding debian:SSL.com_EV_Root_Certification_Authority_ECC.pem\n",
            "Adding debian:Starfield_Services_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:Amazon_Root_CA_2.pem\n",
            "Adding debian:GLOBALTRUST_2020.pem\n",
            "Adding debian:Microsoft_ECC_Root_Certificate_Authority_2017.pem\n",
            "Adding debian:certSIGN_ROOT_CA.pem\n",
            "Adding debian:OISTE_WISeKey_Global_Root_GC_CA.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_G2.pem\n",
            "Adding debian:OISTE_WISeKey_Global_Root_GB_CA.pem\n",
            "Adding debian:ePKI_Root_Certification_Authority.pem\n",
            "Adding debian:Certum_Trusted_Root_CA.pem\n",
            "Adding debian:Security_Communication_ECC_RootCA1.pem\n",
            "Adding debian:Amazon_Root_CA_1.pem\n",
            "Adding debian:ACCVRAIZ1.pem\n",
            "Adding debian:QuoVadis_Root_CA_2.pem\n",
            "Adding debian:TWCA_Global_Root_CA.pem\n",
            "Adding debian:Amazon_Root_CA_3.pem\n",
            "Adding debian:emSign_Root_CA_-_C1.pem\n",
            "Adding debian:DigiCert_Global_Root_CA.pem\n",
            "Adding debian:Security_Communication_RootCA3.pem\n",
            "Adding debian:UCA_Extended_Validation_Root.pem\n",
            "Adding debian:GTS_Root_R1.pem\n",
            "Adding debian:Baltimore_CyberTrust_Root.pem\n",
            "Adding debian:GDCA_TrustAUTH_R5_ROOT.pem\n",
            "Adding debian:Certum_Trusted_Network_CA_2.pem\n",
            "Adding debian:Microsec_e-Szigno_Root_CA_2009.pem\n",
            "Adding debian:NAVER_Global_Root_Certification_Authority.pem\n",
            "Adding debian:GTS_Root_R4.pem\n",
            "Adding debian:Go_Daddy_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:Buypass_Class_3_Root_CA.pem\n",
            "Adding debian:e-Szigno_Root_CA_2017.pem\n",
            "Adding debian:Telia_Root_CA_v2.pem\n",
            "Adding debian:QuoVadis_Root_CA_1_G3.pem\n",
            "Adding debian:Certainly_Root_E1.pem\n",
            "Adding debian:AC_RAIZ_FNMT-RCM.pem\n",
            "Adding debian:DigiCert_TLS_ECC_P384_Root_G5.pem\n",
            "Adding debian:AffirmTrust_Networking.pem\n",
            "Adding debian:COMODO_RSA_Certification_Authority.pem\n",
            "Adding debian:GlobalSign_Root_R46.pem\n",
            "Adding debian:Trustwave_Global_ECC_P384_Certification_Authority.pem\n",
            "Adding debian:TUBITAK_Kamu_SM_SSL_Kok_Sertifikasi_-_Surum_1.pem\n",
            "Adding debian:Go_Daddy_Class_2_CA.pem\n",
            "Adding debian:Certigna_Root_CA.pem\n",
            "Adding debian:vTrus_ECC_Root_CA.pem\n",
            "Adding debian:GlobalSign_ECC_Root_CA_-_R5.pem\n",
            "Adding debian:NetLock_Arany_=Class_Gold=_Főtanúsítvány.pem\n",
            "Adding debian:Microsoft_RSA_Root_Certificate_Authority_2017.pem\n",
            "Adding debian:SZAFIR_ROOT_CA2.pem\n",
            "Adding debian:Certum_Trusted_Network_CA.pem\n",
            "Adding debian:CA_Disig_Root_R2.pem\n",
            "Adding debian:Trustwave_Global_ECC_P256_Certification_Authority.pem\n",
            "Adding debian:Hongkong_Post_Root_CA_3.pem\n",
            "Adding debian:QuoVadis_Root_CA_3_G3.pem\n",
            "Adding debian:SSL.com_Root_Certification_Authority_ECC.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority_-_G4.pem\n",
            "Adding debian:GTS_Root_R2.pem\n",
            "Adding debian:ISRG_Root_X2.pem\n",
            "Adding debian:emSign_ECC_Root_CA_-_C3.pem\n",
            "Adding debian:SwissSign_Silver_CA_-_G2.pem\n",
            "Adding debian:Actalis_Authentication_Root_CA.pem\n",
            "Adding debian:T-TeleSec_GlobalRoot_Class_2.pem\n",
            "Adding debian:ANF_Secure_Server_Root_CA.pem\n",
            "Adding debian:USERTrust_ECC_Certification_Authority.pem\n",
            "Adding debian:COMODO_ECC_Certification_Authority.pem\n",
            "Adding debian:DigiCert_Global_Root_G2.pem\n",
            "Adding debian:Security_Communication_Root_CA.pem\n",
            "Adding debian:AC_RAIZ_FNMT-RCM_SERVIDORES_SEGUROS.pem\n",
            "Adding debian:DigiCert_TLS_RSA4096_Root_G5.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_G3.pem\n",
            "Adding debian:TeliaSonera_Root_CA_v1.pem\n",
            "Adding debian:SecureTrust_CA.pem\n",
            "Adding debian:DigiCert_Trusted_Root_G4.pem\n",
            "Adding debian:Certainly_Root_R1.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority_-_EC1.pem\n",
            "Adding debian:TunTrust_Root_CA.pem\n",
            "Adding debian:IdenTrust_Commercial_Root_CA_1.pem\n",
            "Adding debian:Certigna.pem\n",
            "Adding debian:Amazon_Root_CA_4.pem\n",
            "Adding debian:SwissSign_Gold_CA_-_G2.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_CA.pem\n",
            "Adding debian:AffirmTrust_Premium_ECC.pem\n",
            "Adding debian:Atos_TrustedRoot_2011.pem\n",
            "Adding debian:GlobalSign_Root_CA_-_R3.pem\n",
            "Adding debian:IdenTrust_Public_Sector_Root_CA_1.pem\n",
            "Adding debian:emSign_ECC_Root_CA_-_G3.pem\n",
            "Adding debian:Sectigo_Public_Server_Authentication_Root_R46.pem\n",
            "Adding debian:Atos_TrustedRoot_Root_CA_ECC_TLS_2021.pem\n",
            "Adding debian:Atos_TrustedRoot_Root_CA_RSA_TLS_2021.pem\n",
            "Adding debian:BJCA_Global_Root_CA2.pem\n",
            "Adding debian:BJCA_Global_Root_CA1.pem\n",
            "Adding debian:CommScope_Public_Trust_ECC_Root-01.pem\n",
            "Adding debian:Sectigo_Public_Server_Authentication_Root_E46.pem\n",
            "Adding debian:SSL.com_TLS_ECC_Root_CA_2022.pem\n",
            "Adding debian:SSL.com_TLS_RSA_Root_CA_2022.pem\n",
            "Adding debian:TrustAsia_Global_Root_CA_G4.pem\n",
            "Adding debian:CommScope_Public_Trust_RSA_Root-01.pem\n",
            "Adding debian:CommScope_Public_Trust_RSA_Root-02.pem\n",
            "Adding debian:TrustAsia_Global_Root_CA_G3.pem\n",
            "Adding debian:CommScope_Public_Trust_ECC_Root-02.pem\n",
            "done.\n",
            "Setting up openjdk-17-jdk-headless:amd64 (17.0.16+8~us1-0ubuntu1~22.04.1) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-17-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for ca-certificates (20240203~22.04.1) ...\n",
            "Updating certificates in /etc/ssl/certs...\n",
            "0 added, 0 removed; done.\n",
            "Running hooks in /etc/ca-certificates/update.d...\n",
            "\n",
            "done.\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = (\n",
        "    SparkSession.builder\n",
        "    .appName(\"cs131-youtube-sprint5\")\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"8\")\n",
        "    .config(\"spark.driver.memory\", \"4g\")\n",
        "    .getOrCreate()\n",
        ")\n",
        "\n",
        "print(\"Spark version:\", spark.version)\n"
      ],
      "metadata": {
        "id": "8rOz7BR4p3X-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fc6127e-771a-47a3-e730-370257e845dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark version: 3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!java -version"
      ],
      "metadata": {
        "id": "g3SfqiBCqsT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a8fcf0-2325-4c88-9c0c-1aca5ea83fa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "openjdk version \"17.0.16\" 2025-07-15\n",
            "OpenJDK Runtime Environment (build 17.0.16+8-Ubuntu-0ubuntu122.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 17.0.16+8-Ubuntu-0ubuntu122.04.1, mixed mode, sharing)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"/content/drive/MyDrive/CS 131 Term Project/data\"))\n"
      ],
      "metadata": {
        "id": "ia1QZeSmseYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1862dc0-450d-459c-e7d2-134fbdad2da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cleaned_full_dataset.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Prep\n",
        "\n",
        "Data preparation for your final deliverable (analysis, modeling):\n",
        "Use PySpark meaningfully.\n",
        "\n",
        "Show non-trivial transforms (e.g., groupBy/agg, join, or window)."
      ],
      "metadata": {
        "id": "4TNvtDiiDHQd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "arSoCJoMDG7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "df = (spark.read.option(\"header\", True).csv(\"/content/drive/MyDrive/CS 131 Term Project/data/cleaned_full_dataset.csv\"))\n",
        "df.show(5)\n",
        "print(\"Row count:\", df.count())"
      ],
      "metadata": {
        "id": "g3_5eP4mAl8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "644acad8-06eb-4194-fb92-fe61a503efca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
            "|            video_id|          comment_id|author_display_name|        published_at|like_count|        comment_text|            is_reply|           parent_id|          channel_id|\n",
            "+--------------------+--------------------+-------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
            "|         n_Lv_mw6m6c|UgxoteA9ZjV69ao3w...|      @viktort.6415|2025-09-27T22:11:43Z|         0|next video its hi...|                   0|                NULL|UCgio1HCYjOq7WCy9...|\n",
            "|         n_Lv_mw6m6c|UgwVIjcXJSlw1bdNu...|         @caar_tube|2025-09-27T22:11:13Z|         0|i pray that whoev...|                   0|                NULL|UCBePWH5sTKbTZPeC...|\n",
            "|         n_Lv_mw6m6c|UgwDgmIPkt3zdqFsd...| @Christ.Heroes.888|2025-09-27T22:11:01Z|         0|i knew it was a c...| I'm happy for yo...| you just have th...|                   0|\n",
            "|         n_Lv_mw6m6c|UgyXOOr1fWgF1ZQhr...|       @Bush_Dog777|2025-09-27T22:10:39Z|         0|okay felix is gen...|                NULL|                NULL|                NULL|\n",
            "|I'm actually worr...|                   0|               NULL|UCdKQC3xM9m4vtLUm...|      NULL|                NULL|                NULL|                NULL|                NULL|\n",
            "+--------------------+--------------------+-------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Row count: 301410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqW25Io5uPnr",
        "outputId": "0a37b7c0-b091-4fff-9450-7d9f98a75781"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
            "|            video_id|          comment_id|author_display_name|        published_at|like_count|        comment_text|            is_reply|           parent_id|          channel_id|\n",
            "+--------------------+--------------------+-------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
            "|         n_Lv_mw6m6c|UgxoteA9ZjV69ao3w...|      @viktort.6415|2025-09-27T22:11:43Z|         0|next video its hi...|                   0|                NULL|UCgio1HCYjOq7WCy9...|\n",
            "|         n_Lv_mw6m6c|UgwVIjcXJSlw1bdNu...|         @caar_tube|2025-09-27T22:11:13Z|         0|i pray that whoev...|                   0|                NULL|UCBePWH5sTKbTZPeC...|\n",
            "|         n_Lv_mw6m6c|UgwDgmIPkt3zdqFsd...| @Christ.Heroes.888|2025-09-27T22:11:01Z|         0|i knew it was a c...| I'm happy for yo...| you just have th...|                   0|\n",
            "|         n_Lv_mw6m6c|UgyXOOr1fWgF1ZQhr...|       @Bush_Dog777|2025-09-27T22:10:39Z|         0|okay felix is gen...|                NULL|                NULL|                NULL|\n",
            "|I'm actually worr...|                   0|               NULL|UCdKQC3xM9m4vtLUm...|      NULL|                NULL|                NULL|                NULL|                NULL|\n",
            "|                NULL|                NULL|               NULL|                NULL|      NULL|                NULL|                NULL|                NULL|                NULL|\n",
            "|         n_Lv_mw6m6c|UgyVSx48xDaEwIgWY...|    @donquixote8462|2025-09-27T22:10:06Z|         0|wait till you rea...|                   0|                NULL|UCBxU0wKr8kCxh85w...|\n",
            "|         n_Lv_mw6m6c|Ugwh4YY9xRkFi54EU...|              @0ni_|2025-09-27T22:09:30Z|         0|     i see 3 windows|                   0|                NULL|UCTnNRrAUADc-NY8M...|\n",
            "|         n_Lv_mw6m6c|UgxlHkzzYDm8kMvnG...|@steeltoedcrocs2940|2025-09-27T22:08:59Z|         0|i think all items...|                   0|                NULL|UC0yNcF0IMwKWBX40...|\n",
            "|         n_Lv_mw6m6c|Ugzdog4eXnMpgtesK...|  @RomanRogaOficial|2025-09-27T22:08:02Z|         0|us youtube member...|                   0|                NULL|UCmX8fiFP5ppRTgwM...|\n",
            "+--------------------+--------------------+-------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data cleanup\n",
        "\n",
        "# remove null comment_id's\n",
        "# remove null video id's? and video id's greater than 10 characters/with space characters\n",
        "# remove video with null authors\n",
        "df.createOrReplaceTempView(\"yt_comments\")\n",
        "\n",
        "cleaned_df = spark.sql(\"\"\"\n",
        "SELECT *\n",
        "FROM yt_comments\n",
        "WHERE comment_id IS NOT NULL\n",
        "  AND video_id IS NOT NULL\n",
        "  AND video_id NOT RLIKE '\\\\s'\n",
        "  AND author_display_name IS NOT NULL\n",
        "\"\"\")\n",
        "\n",
        "cleaned_df.show(5)\n",
        "print(\"Row count:\", cleaned_df.count())\n"
      ],
      "metadata": {
        "id": "mrh7IXxJCWuj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac79b1d-af07-404c-c811-9ea248fa8b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+-------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
            "|   video_id|          comment_id|author_display_name|        published_at|like_count|        comment_text|            is_reply|           parent_id|          channel_id|\n",
            "+-----------+--------------------+-------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
            "|n_Lv_mw6m6c|UgxoteA9ZjV69ao3w...|      @viktort.6415|2025-09-27T22:11:43Z|         0|next video its hi...|                   0|                NULL|UCgio1HCYjOq7WCy9...|\n",
            "|n_Lv_mw6m6c|UgwVIjcXJSlw1bdNu...|         @caar_tube|2025-09-27T22:11:13Z|         0|i pray that whoev...|                   0|                NULL|UCBePWH5sTKbTZPeC...|\n",
            "|n_Lv_mw6m6c|UgwDgmIPkt3zdqFsd...| @Christ.Heroes.888|2025-09-27T22:11:01Z|         0|i knew it was a c...| I'm happy for yo...| you just have th...|                   0|\n",
            "|n_Lv_mw6m6c|UgyXOOr1fWgF1ZQhr...|       @Bush_Dog777|2025-09-27T22:10:39Z|         0|okay felix is gen...|                NULL|                NULL|                NULL|\n",
            "|n_Lv_mw6m6c|UgyVSx48xDaEwIgWY...|    @donquixote8462|2025-09-27T22:10:06Z|         0|wait till you rea...|                   0|                NULL|UCBxU0wKr8kCxh85w...|\n",
            "+-----------+--------------------+-------------------+--------------------+----------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Row count: 189843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# additional transformations\n",
        "# make a replies specific df and a parent specific df (only comments that are replies and then only comments that have replies)\n",
        "cleaned_df.createOrReplaceTempView(\"yt_comments_clean\")\n",
        "\n",
        "comment_replies = spark.sql(\"\"\"\n",
        "SELECT *\n",
        "FROM yt_comments_clean\n",
        "WHERE is_reply IS NOT NULL AND is_reply != 0 AND parent_id NOT RLIKE '\\\\s'\n",
        "  OR parent_id IS NOT NULL AND parent_id != 0 AND parent_id NOT RLIKE '\\\\s'\n",
        "\"\"\")\n",
        "\n",
        "comment_replies.show(5)\n",
        "print(\"Row count:\", comment_replies.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaRqi2eRule3",
        "outputId": "dc5e10aa-0ba4-44ee-f3f1-d71e1d7a85d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+--------------------+--------------------+----------+--------------------+--------+--------------------+--------------------+\n",
            "|   video_id|          comment_id| author_display_name|        published_at|like_count|        comment_text|is_reply|           parent_id|          channel_id|\n",
            "+-----------+--------------------+--------------------+--------------------+----------+--------------------+--------+--------------------+--------------------+\n",
            "|n_Lv_mw6m6c|Ugw6x2nh4g7yYhohQ...|@SwitchFBproductions|2025-09-27T21:00:49Z|         1|ok ok felix and h...|       1|Ugw6x2nh4g7yYhohQ...|UCDoQttA32H84ov8F...|\n",
            "|n_Lv_mw6m6c|UgzSFpORGL00H8-nw...|@BlueSquareInWhit...|2025-09-27T19:27:52Z|         0|but whatever floa...|       1|UgzSFpORGL00H8-nw...|UCJkpv9q1-3yMpUNb...|\n",
            "|n_Lv_mw6m6c|UgyolhHq1jzAqPp6p...| @ruslangeorgiev4466|2025-09-27T18:43:43Z|         0|    autism confirmed|       1|UgyolhHq1jzAqPp6p...|UCZMcafEODmuwXn8c...|\n",
            "|n_Lv_mw6m6c|Ugy5NzkjPGOP1LwcW...|         @speed75055|2025-09-27T18:52:37Z|         0|                saar|       1|Ugy5NzkjPGOP1LwcW...|UCQCSHOe-as510XCX...|\n",
            "|n_Lv_mw6m6c|Ugy5NzkjPGOP1LwcW...|          @Rashi-e7c|2025-09-27T19:48:46Z|         0|speed75055 for ex...|       1|Ugy5NzkjPGOP1LwcW...|UC9iZnQWWYDni6nzG...|\n",
            "+-----------+--------------------+--------------------+--------------------+----------+--------------------+--------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Row count: 15232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# group by, join, aggregations\n",
        "\n",
        "# per video statistics\n",
        "video_stats = spark.sql(\"\"\"\n",
        "SELECT\n",
        "  video_id,\n",
        "  COUNT(comment_id) AS total_comments,\n",
        "  SUM(CASE WHEN is_reply = false THEN 1 ELSE 0 END) AS top_level_comments,\n",
        "  SUM(CASE WHEN is_reply = true THEN 1 ELSE 0 END) AS replies,\n",
        "  AVG(like_count) AS avg_comment_likes,\n",
        "  MAX(like_count) AS max_comment_likes\n",
        "FROM yt_comments_clean\n",
        "GROUP BY video_id\n",
        "ORDER BY total_comments DESC\n",
        "\"\"\")\n",
        "video_stats.show(10)\n",
        "print(\"Row count:\", video_stats.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RFlFiAKwLe8",
        "outputId": "0a0c90a4-bf20-425e-8565-29cbe5bf21c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+------------------+-------+------------------+-----------------+\n",
            "|   video_id|total_comments|top_level_comments|replies| avg_comment_likes|max_comment_likes|\n",
            "+-----------+--------------+------------------+-------+------------------+-----------------+\n",
            "|CxVXvFOPIyQ|         28888|             14738|   2800|20.568852118526724|               99|\n",
            "|u_Lxkt50xOg|         27696|             17484|   1653|25.508448873483534|               99|\n",
            "|zQ2ZJuUJeyo|         15247|             11992|    536| 57.16108086836755|              991|\n",
            "|pgeTa1PV_40|          9969|              6852|    334|25.460627946634567|              980|\n",
            "|tZ8ehplVFp4|          9925|              5532|    660|20.739445843828715|               96|\n",
            "|AFXLZ7FEJc4|          8390|              4673|    633|13.705244338498213|             9739|\n",
            "|n_Lv_mw6m6c|          8053|              5249|    424|17.056128150999626|              978|\n",
            "|AGglJehON5g|          7048|              3871|    591| 9.771140749148694|              996|\n",
            "|y2y8ME02lX4|          6970|              4698|    348| 47.67374461979914|             9938|\n",
            "|yzSBeCJfhkw|          6120|              4445|    358| 47.89705882352941|               99|\n",
            "+-----------+--------------+------------------+-------+------------------+-----------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Row count: 2013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# group by channel id\n",
        "# sum likes, count total comments\n",
        "channel_group = spark.sql(\"\"\"\n",
        "SELECT\n",
        "  channel_id,\n",
        "  COUNT(DISTINCT video_id) AS num_videos,\n",
        "  COUNT(comment_id) AS total_comments,\n",
        "  AVG(like_count) AS avg_like_per_comment\n",
        "FROM yt_comments_clean\n",
        "GROUP BY channel_id\n",
        "ORDER BY total_comments DESC\n",
        "\"\"\")\n",
        "channel_group.show(10)\n",
        "print(\"Row count:\", channel_group.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbKcj3fAy7XJ",
        "outputId": "b1302ae5-8abf-451f-d2aa-809d3a55731b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+--------------+--------------------+\n",
            "|          channel_id|num_videos|total_comments|avg_like_per_comment|\n",
            "+--------------------+----------+--------------+--------------------+\n",
            "|                NULL|      1950|         41357|   38.64499987169288|\n",
            "|                   0|       102|          6974|  13.967542725836564|\n",
            "|                   1|        72|          1198|   14.45393634840871|\n",
            "|UCU4f_NDegetve1-w...|         1|            69|0.043478260869565216|\n",
            "|UC3wNIL0HDKiQTMRw...|         6|            66| 0.10606060606060606|\n",
            "|UC1JSyItLCSPAg-hL...|         1|            62| 0.43548387096774194|\n",
            "| I've created the...|         4|            59|    78.1864406779661|\n",
            "|UCHnyfMqiRRG1u-2M...|         4|            57|   47.19298245614035|\n",
            "|UCrRAtu77VEaqlzln...|         1|            49| 0.08163265306122448|\n",
            "|UC43sBpkY6h8G4kz1...|         7|            49|   9.510204081632653|\n",
            "+--------------------+----------+--------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Row count: 121058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# group by author display name\n",
        "# sum likes, replies\n",
        "comment_author_groups = spark.sql(\"\"\"\n",
        "SELECT\n",
        "  author_display_name,\n",
        "  COUNT(comment_id) AS total_comments,\n",
        "  SUM(like_count) AS total_likes,\n",
        "  AVG(like_count) AS avg_likes_per_comment\n",
        "FROM yt_comments_clean\n",
        "GROUP BY author_display_name\n",
        "ORDER BY total_comments DESC\n",
        "\"\"\")\n",
        "comment_author_groups.show(10)\n",
        "print(\"Row count:\", comment_author_groups.count())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddBNH_mQy4x0",
        "outputId": "5c9196cb-e4b0-4e4f-d918-70849e561900"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+--------------+-----------+---------------------+\n",
            "|author_display_name|total_comments|total_likes|avg_likes_per_comment|\n",
            "+-------------------+--------------+-----------+---------------------+\n",
            "|                  0|           796|       NULL|                 NULL|\n",
            "|                  1|           108|       NULL|                 NULL|\n",
            "|      @LarsLarsen77|            97|       31.0|  0.31958762886597936|\n",
            "|       @ashleyr6809|            70|        7.0|                  0.1|\n",
            "|@JohnBenjamin-ju6zd|            69|        3.0| 0.043478260869565216|\n",
            "|        @veritasium|            66|   176211.0|   2669.8636363636365|\n",
            "|   @VideoHouseExtra|            63|       21.0|   0.3333333333333333|\n",
            "|        @RadinWaves|            60|        4.0|  0.06666666666666667|\n",
            "|        @anibration|            58|       54.0|   0.9310344827586207|\n",
            "|      @Mikael-uk7rv|            57|      467.0|    8.192982456140351|\n",
            "+-------------------+--------------+-----------+---------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Row count: 154059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# group by published date\n",
        "# aggregate likes by date?\n",
        "publish_date_groups = spark.sql(\"\"\"\n",
        "SELECT\n",
        "  DATE(published_at) AS date,\n",
        "  COUNT(*) AS comment_count,\n",
        "  AVG(like_count) AS avg_likes\n",
        "FROM yt_comments_clean\n",
        "GROUP BY DATE(published_at)\n",
        "ORDER BY date\n",
        "\"\"\")\n",
        "publish_date_groups.show(10)\n",
        "print(\"Row count:\", publish_date_groups.count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZIFfEm3y3K4",
        "outputId": "172f8e43-d34b-4d8a-bb2c-37b852cd4623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+------------------+\n",
            "|      date|comment_count|         avg_likes|\n",
            "+----------+-------------+------------------+\n",
            "|      NULL|         2670| 3.402754491017964|\n",
            "|2025-04-13|           27|2.7037037037037037|\n",
            "|2025-04-14|           21| 6.285714285714286|\n",
            "|2025-04-15|            6|               1.0|\n",
            "|2025-04-16|            2|               0.0|\n",
            "|2025-04-17|            1|               0.0|\n",
            "|2025-04-23|            1|               1.0|\n",
            "|2025-04-30|         1148|24.094076655052266|\n",
            "|2025-05-01|          485|2.2082474226804125|\n",
            "|2025-05-02|          204|1.9166666666666667|\n",
            "+----------+-------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Row count: 158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rebuild PA2 / PA3 tables\n",
        "\n",
        "\n",
        "- STEP 3A — Top-N and Skinny Tables\n",
        "- STEP 3B — Ratios, Buckets\"\n",
        "- STEP 3C — quality filters, month-level\"\n",
        "- STEP 3D — 2 frequency tables\n",
        "- STEP 4 — one runnable entry script or notebook\n",
        "\n"
      ],
      "metadata": {
        "id": "OXd2FqyKHlto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_channel_id = spark.sql(\"\"\"\n",
        "SELECT\n",
        "  channel_id,\n",
        "  COUNT(DISTINCT video_id) AS num_videos\n",
        "FROM yt_comments_clean\n",
        "WHERE channel_id LIKE 'UC%'\n",
        "GROUP BY channel_id\n",
        "ORDER BY num_videos DESC\n",
        "\"\"\")\n",
        "top_channel_id.show(10)\n",
        "print(\"Row count:\", top_channel_id.count())"
      ],
      "metadata": {
        "id": "vTM51eKyy9N7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e15596ac-cb05-4088-8cb5-f8b150eb862a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+\n",
            "|          channel_id|num_videos|\n",
            "+--------------------+----------+\n",
            "|UCuQvF0AcTMeqoP1F...|        13|\n",
            "|UCSu7wuRTWsdWF9V7...|        12|\n",
            "|UClFDTPiMwDQpppSO...|        11|\n",
            "|UCCsU8TTJPJ05jucH...|        11|\n",
            "|UCnJevl-xdTBTztQC...|        10|\n",
            "|UC_LYdQ4p2CVb4vke...|        10|\n",
            "|UCm7Kj2jVRrcmzVVL...|         9|\n",
            "|UCPohpmvVnar6pn9q...|         9|\n",
            "|UCe2sZdoutqb9AJ8g...|         9|\n",
            "|UCcwljD8q95aNSBZk...|         9|\n",
            "+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Row count: 109969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# frequency of videos published by date\n",
        "freq_dates = spark.sql(\"\"\"\n",
        "SELECT\n",
        "  DATE(published_at) AS date,\n",
        "  COUNT(DISTINCT video_id) AS num_videos\n",
        "FROM yt_comments_clean\n",
        "WHERE published_at IS NOT NULL AND channel_id LIKE 'UC%'\n",
        "GROUP BY DATE(published_at)\n",
        "ORDER BY num_videos DESC\n",
        "\"\"\")\n",
        "freq_dates.show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMnkrmdpE6Oo",
        "outputId": "f6bc8cc9-09fd-44f0-be29-bee621c494c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|      date|num_videos|\n",
            "+----------+----------+\n",
            "|2025-09-27|        60|\n",
            "|2025-09-25|        55|\n",
            "|2025-09-26|        54|\n",
            "|2025-09-24|        47|\n",
            "|2025-09-22|        43|\n",
            "|2025-09-21|        41|\n",
            "|2025-09-19|        41|\n",
            "|2025-09-20|        36|\n",
            "|2025-09-23|        36|\n",
            "|2025-09-18|        35|\n",
            "|2025-09-11|        34|\n",
            "|      NULL|        33|\n",
            "|2025-09-13|        32|\n",
            "|2025-09-09|        30|\n",
            "|2025-09-17|        30|\n",
            "|2025-09-10|        30|\n",
            "|2025-09-15|        29|\n",
            "|2025-09-08|        27|\n",
            "|2025-09-12|        27|\n",
            "|2025-09-07|        25|\n",
            "+----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top-N entity list WITH counts (top videos by comment count)\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "video_window = Window.orderBy(F.col(\"total_comments\").desc())\n",
        "\n",
        "top_videos = spark.sql(\"\"\"\n",
        "SELECT\n",
        "  video_id,\n",
        "  COUNT(comment_id) AS total_comments\n",
        "FROM yt_comments_clean\n",
        "GROUP BY video_id\n",
        "\"\"\")\n",
        "\n",
        "top_videos = top_videos.withColumn(\"rank\", F.row_number().over(video_window))\n",
        "\n",
        "top_videos.show(10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2fQAHqVGFVX",
        "outputId": "3f919428-103a-40fd-8fff-7c3845176620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+----+\n",
            "|   video_id|total_comments|rank|\n",
            "+-----------+--------------+----+\n",
            "|CxVXvFOPIyQ|         28888|   1|\n",
            "|u_Lxkt50xOg|         27696|   2|\n",
            "|zQ2ZJuUJeyo|         15247|   3|\n",
            "|pgeTa1PV_40|          9969|   4|\n",
            "|tZ8ehplVFp4|          9925|   5|\n",
            "|AFXLZ7FEJc4|          8390|   6|\n",
            "|n_Lv_mw6m6c|          8053|   7|\n",
            "|AGglJehON5g|          7048|   8|\n",
            "|y2y8ME02lX4|          6970|   9|\n",
            "|yzSBeCJfhkw|          6120|  10|\n",
            "+-----------+--------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# top-30 videos by comment count, select only top 30\n",
        "top_30_videos = spark.sql(\"\"\"\n",
        "SELECT\n",
        "  video_id,\n",
        "  COUNT(comment_id) AS total_comments\n",
        "FROM yt_comments_clean\n",
        "GROUP BY video_id\n",
        "ORDER BY total_comments DESC\n",
        "LIMIT 30\n",
        "\"\"\")\n",
        "top_30_videos = top_30_videos.withColumn(\"rank\", F.row_number().over(video_window))\n",
        "\n",
        "top_30_videos.show(31) #just to show all 30 rows when printing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUimEVliI6jD",
        "outputId": "ed0b68dc-daa7-4ecd-ec74-7b70183636c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+----+\n",
            "|   video_id|total_comments|rank|\n",
            "+-----------+--------------+----+\n",
            "|CxVXvFOPIyQ|         28888|   1|\n",
            "|u_Lxkt50xOg|         27696|   2|\n",
            "|zQ2ZJuUJeyo|         15247|   3|\n",
            "|pgeTa1PV_40|          9969|   4|\n",
            "|tZ8ehplVFp4|          9925|   5|\n",
            "|AFXLZ7FEJc4|          8390|   6|\n",
            "|n_Lv_mw6m6c|          8053|   7|\n",
            "|AGglJehON5g|          7048|   8|\n",
            "|y2y8ME02lX4|          6970|   9|\n",
            "|yzSBeCJfhkw|          6120|  10|\n",
            "|wG-o4rk_W64|          4067|  11|\n",
            "|MhRGfNkw3Vo|          3830|  12|\n",
            "|oUR6V4dQMmM|          3186|  13|\n",
            "|4T4AoXFDcD8|          2979|  14|\n",
            "|RQWpF2Gb-gU|          2544|  15|\n",
            "|OW9Mq3wrEqY|          2329|  16|\n",
            "|AEHc8jrcc6g|          2220|  17|\n",
            "|ly6YKz9UfQ4|          1980|  18|\n",
            "|8tx2viHpgA8|          1925|  19|\n",
            "|XwhGk4c4bT8|          1837|  20|\n",
            "|OoU1OY9clvo|          1778|  21|\n",
            "|lNumJwHpXIA|          1700|  22|\n",
            "|GOejI6c0CMQ|          1609|  23|\n",
            "|7Xib58aLHUU|          1568|  24|\n",
            "|iv-5mZ_9CPY|          1390|  25|\n",
            "|DC2p3kFjcK0|          1377|  26|\n",
            "|q6WlXhtVvkg|          1345|  27|\n",
            "|yJPvEQ8EBJc|          1237|  28|\n",
            "|8_GgeASwHwQ|          1156|  29|\n",
            "|ZTGSWSEXV_g|          1120|  30|\n",
            "+-----------+--------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count frequency of comments containing the word \"great\" per video\n",
        "great_in_comments = spark.sql(\"\"\"\n",
        "SELECT\n",
        "  video_id,\n",
        "  COUNT(comment_id) AS great_comment_count\n",
        "FROM yt_comments_clean\n",
        "WHERE comment_text LIKE '%great%'\n",
        "GROUP BY video_id\n",
        "ORDER BY great_comment_count DESC\n",
        "\"\"\")\n",
        "print(\"'Great' commnents Row count:\", great_in_comments.count())\n",
        "great_in_comments.show(10)\n",
        "\n",
        "# count frequency of comments containing the word \"great\" per video\n",
        "bad_in_comments = spark.sql(\"\"\"\n",
        "SELECT\n",
        "  video_id,\n",
        "  COUNT(comment_id) AS great_comment_count\n",
        "FROM yt_comments_clean\n",
        "WHERE comment_text LIKE '%bad%'\n",
        "GROUP BY video_id\n",
        "ORDER BY great_comment_count DESC\n",
        "\"\"\")\n",
        "print(\"'Bad' comments Row count:\", bad_in_comments.count())\n",
        "bad_in_comments.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T41aj7I8GiOl",
        "outputId": "cada657b-e8ee-4a19-9ec3-9edb6f8871d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Great' commnents Row count: 81\n",
            "+-----------+-------------------+\n",
            "|   video_id|great_comment_count|\n",
            "+-----------+-------------------+\n",
            "|CxVXvFOPIyQ|                641|\n",
            "|u_Lxkt50xOg|                410|\n",
            "|pgeTa1PV_40|                169|\n",
            "|AGglJehON5g|                150|\n",
            "|tZ8ehplVFp4|                133|\n",
            "|AFXLZ7FEJc4|                121|\n",
            "|yzSBeCJfhkw|                 80|\n",
            "|zQ2ZJuUJeyo|                 73|\n",
            "|n_Lv_mw6m6c|                 72|\n",
            "|RQWpF2Gb-gU|                 64|\n",
            "+-----------+-------------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "'Bad' comments Row count: 67\n",
            "+-----------+-------------------+\n",
            "|   video_id|great_comment_count|\n",
            "+-----------+-------------------+\n",
            "|CxVXvFOPIyQ|                344|\n",
            "|u_Lxkt50xOg|                180|\n",
            "|y2y8ME02lX4|                128|\n",
            "|tZ8ehplVFp4|                 78|\n",
            "|AFXLZ7FEJc4|                 68|\n",
            "|zQ2ZJuUJeyo|                 62|\n",
            "|AGglJehON5g|                 58|\n",
            "|yzSBeCJfhkw|                 53|\n",
            "|pgeTa1PV_40|                 49|\n",
            "|MhRGfNkw3Vo|                 36|\n",
            "+-----------+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# separate comment date and time\n",
        "from pyspark.sql.functions import split, regexp_replace\n",
        "\n",
        "comment_date_time = spark.sql(\"\"\"\n",
        "SELECT\n",
        "  *\n",
        "FROM yt_comments_clean\n",
        "\"\"\")\n",
        "\n",
        "comment_date_time = comment_date_time.withColumn(\"date\", split(comment_date_time[\"published_at\"], \"T\").getItem(0))\n",
        "comment_date_time = comment_date_time.withColumn(\"time\", regexp_replace(split(comment_date_time[\"published_at\"], \"T\").getItem(1), \"Z\", \"\"))\n",
        "comment_date_time = comment_date_time.drop(\"published_at\")\n",
        "\n",
        "comment_date_time.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozgm7ORpJ7pR",
        "outputId": "42a7b700-320e-4757-db93-126a9eb12de3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+-------------------+----------+--------------------+--------------------+--------------------+--------------------+----------+--------+\n",
            "|   video_id|          comment_id|author_display_name|like_count|        comment_text|            is_reply|           parent_id|          channel_id|      date|    time|\n",
            "+-----------+--------------------+-------------------+----------+--------------------+--------------------+--------------------+--------------------+----------+--------+\n",
            "|n_Lv_mw6m6c|UgxoteA9ZjV69ao3w...|      @viktort.6415|         0|next video its hi...|                   0|                NULL|UCgio1HCYjOq7WCy9...|2025-09-27|22:11:43|\n",
            "|n_Lv_mw6m6c|UgwVIjcXJSlw1bdNu...|         @caar_tube|         0|i pray that whoev...|                   0|                NULL|UCBePWH5sTKbTZPeC...|2025-09-27|22:11:13|\n",
            "|n_Lv_mw6m6c|UgwDgmIPkt3zdqFsd...| @Christ.Heroes.888|         0|i knew it was a c...| I'm happy for yo...| you just have th...|                   0|2025-09-27|22:11:01|\n",
            "|n_Lv_mw6m6c|UgyXOOr1fWgF1ZQhr...|       @Bush_Dog777|         0|okay felix is gen...|                NULL|                NULL|                NULL|2025-09-27|22:10:39|\n",
            "|n_Lv_mw6m6c|UgyVSx48xDaEwIgWY...|    @donquixote8462|         0|wait till you rea...|                   0|                NULL|UCBxU0wKr8kCxh85w...|2025-09-27|22:10:06|\n",
            "+-----------+--------------------+-------------------+----------+--------------------+--------------------+--------------------+--------------------+----------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ced10be",
        "outputId": "1b7a9c63-b708-46b6-ea98-56fa316feb66"
      },
      "source": [
        "# define sentiment keywords\n",
        "negative_keywords = ['bad', 'hate', 'terrible', 'worst', 'poor', 'dislike', 'awful', 'negative', 'frustrating', 'annoying', 'disappointing', 'horrible', 'trash', 'sucks', 'fail', 'stupid', 'ridiculous', 'pathetic']\n",
        "neutral_keywords = ['maybe', 'perhaps', 'also', 'and', 'but', 'or', 'so', 'then', 'just', 'yet', 'however', 'indeed', 'whether', 'meanwhile', 'regardless', 'either', 'neither', 'somewhat', 'a bit']\n",
        "positive_keywords = ['good', 'love', 'great', 'best', 'excellent', 'amazing', 'fantastic', 'awesome', 'positive', 'happy', 'enjoy', 'like', 'super', 'wonderful', 'beautiful', 'perfect', 'brilliant', 'delightful', 'cool', 'nice']\n",
        "\n",
        "print(\"Sentiment keyword lists defined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment keyword lists defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e11700df",
        "outputId": "4d662f99-0635-46eb-b287-eeba0699a9e3"
      },
      "source": [
        "# filter comments by specific video\n",
        "filtered_comments_df = comment_date_time.filter(comment_date_time.video_id == 'n_Lv_mw6m6c')\n",
        "filtered_comments_df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+-------------------+----------+--------------------+--------------------+--------------------+--------------------+----------+--------+\n",
            "|   video_id|          comment_id|author_display_name|like_count|        comment_text|            is_reply|           parent_id|          channel_id|      date|    time|\n",
            "+-----------+--------------------+-------------------+----------+--------------------+--------------------+--------------------+--------------------+----------+--------+\n",
            "|n_Lv_mw6m6c|UgxoteA9ZjV69ao3w...|      @viktort.6415|         0|next video its hi...|                   0|                NULL|UCgio1HCYjOq7WCy9...|2025-09-27|22:11:43|\n",
            "|n_Lv_mw6m6c|UgwVIjcXJSlw1bdNu...|         @caar_tube|         0|i pray that whoev...|                   0|                NULL|UCBePWH5sTKbTZPeC...|2025-09-27|22:11:13|\n",
            "|n_Lv_mw6m6c|UgwDgmIPkt3zdqFsd...| @Christ.Heroes.888|         0|i knew it was a c...| I'm happy for yo...| you just have th...|                   0|2025-09-27|22:11:01|\n",
            "|n_Lv_mw6m6c|UgyXOOr1fWgF1ZQhr...|       @Bush_Dog777|         0|okay felix is gen...|                NULL|                NULL|                NULL|2025-09-27|22:10:39|\n",
            "|n_Lv_mw6m6c|UgyVSx48xDaEwIgWY...|    @donquixote8462|         0|wait till you rea...|                   0|                NULL|UCBxU0wKr8kCxh85w...|2025-09-27|22:10:06|\n",
            "+-----------+--------------------+-------------------+----------+--------------------+--------------------+--------------------+--------------------+----------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bd36ab8",
        "outputId": "be6e0106-59a4-43ce-a2e2-be31865fe11a"
      },
      "source": [
        "# determine sentiment of comment\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "def classify_sentiment(comment):\n",
        "    if comment is None:\n",
        "        return \"unknown\"\n",
        "    comment_lower = comment.lower()\n",
        "\n",
        "    has_positive = any(keyword in comment_lower for keyword in positive_keywords)\n",
        "    has_negative = any(keyword in comment_lower for keyword in negative_keywords)\n",
        "\n",
        "    if has_positive and not has_negative:\n",
        "        return \"positive\"\n",
        "    elif has_negative and not has_positive:\n",
        "        return \"negative\"\n",
        "    elif not has_positive and not has_negative:\n",
        "\n",
        "        has_neutral = any(keyword in comment_lower for keyword in neutral_keywords)\n",
        "        if has_neutral:\n",
        "            return \"neutral\"\n",
        "        else:\n",
        "            return \"unknown\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "sentiment_udf = udf(classify_sentiment, StringType())\n",
        "\n",
        "sentiment_classified_df = filtered_comments_df.withColumn(\"sentiment\", sentiment_udf(filtered_comments_df.comment_text))\n",
        "\n",
        "sentiment_classified_df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------------+-------------------+----------+--------------------+--------------------+--------------------+--------------------+----------+--------+---------+\n",
            "|   video_id|          comment_id|author_display_name|like_count|        comment_text|            is_reply|           parent_id|          channel_id|      date|    time|sentiment|\n",
            "+-----------+--------------------+-------------------+----------+--------------------+--------------------+--------------------+--------------------+----------+--------+---------+\n",
            "|n_Lv_mw6m6c|UgxoteA9ZjV69ao3w...|      @viktort.6415|         0|next video its hi...|                   0|                NULL|UCgio1HCYjOq7WCy9...|2025-09-27|22:11:43|  neutral|\n",
            "|n_Lv_mw6m6c|UgwVIjcXJSlw1bdNu...|         @caar_tube|         0|i pray that whoev...|                   0|                NULL|UCBePWH5sTKbTZPeC...|2025-09-27|22:11:13| positive|\n",
            "|n_Lv_mw6m6c|UgwDgmIPkt3zdqFsd...| @Christ.Heroes.888|         0|i knew it was a c...| I'm happy for yo...| you just have th...|                   0|2025-09-27|22:11:01|  unknown|\n",
            "|n_Lv_mw6m6c|UgyXOOr1fWgF1ZQhr...|       @Bush_Dog777|         0|okay felix is gen...|                NULL|                NULL|                NULL|2025-09-27|22:10:39|  unknown|\n",
            "|n_Lv_mw6m6c|UgyVSx48xDaEwIgWY...|    @donquixote8462|         0|wait till you rea...|                   0|                NULL|UCBxU0wKr8kCxh85w...|2025-09-27|22:10:06|  unknown|\n",
            "+-----------+--------------------+-------------------+----------+--------------------+--------------------+--------------------+--------------------+----------+--------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a081cf6a",
        "outputId": "d1c3db6c-dec8-4935-a917-88cb37ab12d4"
      },
      "source": [
        "#user defined function for extracting keywords from comments\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType, ArrayType, StructType\n",
        "\n",
        "def extract_keywords(comment_text):\n",
        "    if comment_text is None:\n",
        "        return []\n",
        "\n",
        "    comment_lower = comment_text.lower()\n",
        "\n",
        "    found_negative = set()\n",
        "    found_neutral = set()\n",
        "    found_positive = set()\n",
        "\n",
        "    for keyword in negative_keywords:\n",
        "        if keyword in comment_lower:\n",
        "            found_negative.add(keyword)\n",
        "\n",
        "    for keyword in neutral_keywords:\n",
        "        if keyword in comment_lower:\n",
        "            found_neutral.add(keyword)\n",
        "\n",
        "    for keyword in positive_keywords:\n",
        "        if keyword in comment_lower:\n",
        "            found_positive.add(keyword)\n",
        "\n",
        "    result = []\n",
        "    for keyword in found_negative:\n",
        "        result.append((keyword, 'negative'))\n",
        "    for keyword in found_neutral:\n",
        "        result.append((keyword, 'neutral'))\n",
        "    for keyword in found_positive:\n",
        "        result.append((keyword, 'positive'))\n",
        "\n",
        "    return result\n",
        "\n",
        "keyword_sentiment_schema = ArrayType(StructType([\n",
        "    StructField(\"keyword\", StringType(), True),\n",
        "    StructField(\"keyword_family\", StringType(), True)\n",
        "]))\n",
        "\n",
        "extract_keywords_udf = udf(extract_keywords, ArrayType(StructType([\n",
        "    StructField(\"keyword\", StringType(), True),\n",
        "    StructField(\"keyword_family\", StringType(), True)\n",
        "])))\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\'extract_keywords\\' function defined and registered as \\'extract_keywords_udf\\'.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'extract_keywords' function defined and registered as 'extract_keywords_udf'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b858307",
        "outputId": "7b433ec4-5419-42c9-f3ae-5438c58744ea"
      },
      "source": [
        "extracted_keywords_df = filtered_comments_df.withColumn(\"extracted_keywords\", extract_keywords_udf(filtered_comments_df.comment_text))\n",
        "\n",
        "extracted_keywords_df.printSchema()\n",
        "extracted_keywords_df.show(5, truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- video_id: string (nullable = true)\n",
            " |-- comment_id: string (nullable = true)\n",
            " |-- author_display_name: string (nullable = true)\n",
            " |-- like_count: string (nullable = true)\n",
            " |-- comment_text: string (nullable = true)\n",
            " |-- is_reply: string (nullable = true)\n",
            " |-- parent_id: string (nullable = true)\n",
            " |-- channel_id: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- time: string (nullable = true)\n",
            " |-- extracted_keywords: array (nullable = true)\n",
            " |    |-- element: struct (containsNull = true)\n",
            " |    |    |-- keyword: string (nullable = true)\n",
            " |    |    |-- keyword_family: string (nullable = true)\n",
            "\n",
            "+-----------+--------------------------+-------------------+----------+-------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------+------------------------+----------+--------+------------------------------------------------+\n",
            "|video_id   |comment_id                |author_display_name|like_count|comment_text                                                                   |is_reply                                                                                      |parent_id                                                                                   |channel_id              |date      |time    |extracted_keywords                              |\n",
            "+-----------+--------------------------+-------------------+----------+-------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------+------------------------+----------+--------+------------------------------------------------+\n",
            "|n_Lv_mw6m6c|UgxoteA9ZjV69ao3wzd4AaABAg|@viktort.6415      |0         |next video its him standing in an empty room looking maniacally                |0                                                                                             |NULL                                                                                        |UCgio1HCYjOq7WCy9vjjA_6g|2025-09-27|22:11:43|[{and, neutral}]                                |\n",
            "|n_Lv_mw6m6c|UgwVIjcXJSlw1bdNuAJ4AaABAg|@caar_tube         |0         |i pray that whoever subscribes will have something good happen to them tomorrow|0                                                                                             |NULL                                                                                        |UCBePWH5sTKbTZPeCmCrWhcw|2025-09-27|22:11:13|[{or, neutral}, {so, neutral}, {good, positive}]|\n",
            "|n_Lv_mw6m6c|UgwDgmIPkt3zdqFsd2p4AaABAg|@Christ.Heroes.888 |0         |i knew it was a clickbait                                                      | I'm happy for you. You will find balance. All people make decisions and changes at some point| you just have the privilege of having a few million strangers criticizing your every move.\"|0                       |2025-09-27|22:11:01|[]                                              |\n",
            "|n_Lv_mw6m6c|UgyXOOr1fWgF1ZQhrzR4AaABAg|@Bush_Dog777       |0         |okay felix is genuinely going crazy                                            |NULL                                                                                          |NULL                                                                                        |NULL                    |2025-09-27|22:10:39|[]                                              |\n",
            "|n_Lv_mw6m6c|UgyVSx48xDaEwIgWY-B4AaABAg|@donquixote8462    |0         |wait till you read about the monastic church fathers of ancient christianity   |0                                                                                             |NULL                                                                                        |UCBxU0wKr8kCxh85wZaP7p-g|2025-09-27|22:10:06|[]                                              |\n",
            "+-----------+--------------------------+-------------------+----------+-------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------+------------------------+----------+--------+------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3ea35cd",
        "outputId": "82f921bc-8b1d-48ca-9719-e0a5e6666a45"
      },
      "source": [
        "# create extracted keywords df\n",
        "from pyspark.sql.functions import explode\n",
        "\n",
        "keywords_extracted_df = sentiment_classified_df.withColumn(\n",
        "    \"extracted_keywords\", extract_keywords_udf(sentiment_classified_df.comment_text)\n",
        ")\n",
        "\n",
        "exploded_keywords_df = keywords_extracted_df.withColumn(\n",
        "    \"exploded_keyword\", explode(\"extracted_keywords\")\n",
        ").select(\n",
        "    keywords_extracted_df[\"*\"],\n",
        "    F.col(\"exploded_keyword.keyword\"),\n",
        "    F.col(\"exploded_keyword.keyword_family\")\n",
        ").drop(\"extracted_keywords\", \"exploded_keyword\")\n",
        "\n",
        "exploded_keywords_df.printSchema()\n",
        "\n",
        "exploded_keywords_df.show(5, truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- video_id: string (nullable = true)\n",
            " |-- comment_id: string (nullable = true)\n",
            " |-- author_display_name: string (nullable = true)\n",
            " |-- like_count: string (nullable = true)\n",
            " |-- comment_text: string (nullable = true)\n",
            " |-- is_reply: string (nullable = true)\n",
            " |-- parent_id: string (nullable = true)\n",
            " |-- channel_id: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- time: string (nullable = true)\n",
            " |-- sentiment: string (nullable = true)\n",
            " |-- keyword: string (nullable = true)\n",
            " |-- keyword_family: string (nullable = true)\n",
            "\n",
            "+-----------+--------------------------+-------------------+----------+------------------------------------------------------------------------------------+--------+---------+------------------------+----------+--------+---------+-------+--------------+\n",
            "|video_id   |comment_id                |author_display_name|like_count|comment_text                                                                        |is_reply|parent_id|channel_id              |date      |time    |sentiment|keyword|keyword_family|\n",
            "+-----------+--------------------------+-------------------+----------+------------------------------------------------------------------------------------+--------+---------+------------------------+----------+--------+---------+-------+--------------+\n",
            "|n_Lv_mw6m6c|UgxoteA9ZjV69ao3wzd4AaABAg|@viktort.6415      |0         |next video its him standing in an empty room looking maniacally                     |0       |NULL     |UCgio1HCYjOq7WCy9vjjA_6g|2025-09-27|22:11:43|neutral  |and    |neutral       |\n",
            "|n_Lv_mw6m6c|UgwVIjcXJSlw1bdNuAJ4AaABAg|@caar_tube         |0         |i pray that whoever subscribes will have something good happen to them tomorrow     |0       |NULL     |UCBePWH5sTKbTZPeCmCrWhcw|2025-09-27|22:11:13|positive |or     |neutral       |\n",
            "|n_Lv_mw6m6c|UgwVIjcXJSlw1bdNuAJ4AaABAg|@caar_tube         |0         |i pray that whoever subscribes will have something good happen to them tomorrow     |0       |NULL     |UCBePWH5sTKbTZPeCmCrWhcw|2025-09-27|22:11:13|positive |so     |neutral       |\n",
            "|n_Lv_mw6m6c|UgwVIjcXJSlw1bdNuAJ4AaABAg|@caar_tube         |0         |i pray that whoever subscribes will have something good happen to them tomorrow     |0       |NULL     |UCBePWH5sTKbTZPeCmCrWhcw|2025-09-27|22:11:13|positive |good   |positive      |\n",
            "|n_Lv_mw6m6c|UgxlHkzzYDm8kMvnGmJ4AaABAg|@steeltoedcrocs2940|0         |i think all items in his home are a bowl and he needs to live in complete simplicity|0       |NULL     |UC0yNcF0IMwKWBX40Wa9H8Cw|2025-09-27|22:08:59|neutral  |and    |neutral       |\n",
            "+-----------+--------------------------+-------------------+----------+------------------------------------------------------------------------------------+--------+---------+------------------------+----------+--------+---------+-------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baaee4bd",
        "outputId": "6a3febdb-53fc-4551-a9dc-3f31c2052bd4"
      },
      "source": [
        "# count keyword occurences per comment\n",
        "keyword_counts_df = exploded_keywords_df.groupBy(\"video_id\", \"keyword_family\", \"keyword\").count()\n",
        "keyword_counts_df = keyword_counts_df.orderBy(F.col(\"count\").desc())\n",
        "\n",
        "keyword_counts_df.show(10)\n",
        "print(\"Row count:\", keyword_counts_df.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+-------+-----+\n",
            "|   video_id|keyword_family|keyword|count|\n",
            "+-----------+--------------+-------+-----+\n",
            "|n_Lv_mw6m6c|       neutral|     or| 1627|\n",
            "|n_Lv_mw6m6c|       neutral|     so| 1053|\n",
            "|n_Lv_mw6m6c|       neutral|    and|  915|\n",
            "|n_Lv_mw6m6c|       neutral|   just|  432|\n",
            "|n_Lv_mw6m6c|      positive|   like|  351|\n",
            "|n_Lv_mw6m6c|       neutral|    but|  295|\n",
            "|n_Lv_mw6m6c|      positive|   love|  197|\n",
            "|n_Lv_mw6m6c|      positive|   good|  151|\n",
            "|n_Lv_mw6m6c|       neutral|   also|  118|\n",
            "|n_Lv_mw6m6c|       neutral|   then|  102|\n",
            "+-----------+--------------+-------+-----+\n",
            "only showing top 10 rows\n",
            "\n",
            "Row count: 53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dc6c8dd",
        "outputId": "119901bd-7199-477e-8bda-4c0a2ac446df"
      },
      "source": [
        "# create keyword dataframe\n",
        "all_keywords_data = []\n",
        "\n",
        "for keyword in negative_keywords:\n",
        "    all_keywords_data.append((keyword, 'negative'))\n",
        "\n",
        "for keyword in neutral_keywords:\n",
        "    all_keywords_data.append((keyword, 'neutral'))\n",
        "\n",
        "for keyword in positive_keywords:\n",
        "    all_keywords_data.append((keyword, 'positive'))\n",
        "\n",
        "all_keywords_df = spark.createDataFrame(all_keywords_data, [\"keyword\", \"keyword_family\"])\n",
        "\n",
        "all_keywords_df.show(10)\n",
        "print(\"Row count:\", all_keywords_df.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------------+\n",
            "|    keyword|keyword_family|\n",
            "+-----------+--------------+\n",
            "|        bad|      negative|\n",
            "|       hate|      negative|\n",
            "|   terrible|      negative|\n",
            "|      worst|      negative|\n",
            "|       poor|      negative|\n",
            "|    dislike|      negative|\n",
            "|      awful|      negative|\n",
            "|   negative|      negative|\n",
            "|frustrating|      negative|\n",
            "|   annoying|      negative|\n",
            "+-----------+--------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "Row count: 57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2499d989",
        "outputId": "1a08e418-50a5-4445-f5f0-a164dcada176"
      },
      "source": [
        "# displaying final results by joining the keyword families with extracted comments keywords, sorting the families and counts\n",
        "\n",
        "from pyspark.sql.functions import lit\n",
        "\n",
        "final_keyword_analysis_df = all_keywords_df.join(\n",
        "    keyword_counts_df,\n",
        "    on=[\"keyword\", \"keyword_family\"],\n",
        "    how=\"left_outer\"\n",
        ")\n",
        "\n",
        "final_keyword_analysis_df = final_keyword_analysis_df.withColumn(\n",
        "    \"video_id\",\n",
        "    F.when(F.col(\"video_id\").isNull(), lit(\"n_Lv_mw6m6c\")).otherwise(F.col(\"video_id\"))\n",
        ").withColumn(\n",
        "    \"count\",\n",
        "    F.when(F.col(\"count\").isNull(), lit(0)).otherwise(F.col(\"count\"))\n",
        ").orderBy(F.col(\"keyword_family\"), F.col(\"count\").desc())\n",
        "\n",
        "final_keyword_analysis_df.show(60)\n",
        "print(\"Row count:\", final_keyword_analysis_df.count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------+-----------+-----+\n",
            "|      keyword|keyword_family|   video_id|count|\n",
            "+-------------+--------------+-----------+-----+\n",
            "|         poor|      negative|n_Lv_mw6m6c|   81|\n",
            "|         hate|      negative|n_Lv_mw6m6c|   34|\n",
            "|          bad|      negative|n_Lv_mw6m6c|   27|\n",
            "|       stupid|      negative|n_Lv_mw6m6c|   26|\n",
            "|     annoying|      negative|n_Lv_mw6m6c|    5|\n",
            "|        worst|      negative|n_Lv_mw6m6c|    3|\n",
            "|        awful|      negative|n_Lv_mw6m6c|    3|\n",
            "|        trash|      negative|n_Lv_mw6m6c|    3|\n",
            "|   ridiculous|      negative|n_Lv_mw6m6c|    3|\n",
            "|     terrible|      negative|n_Lv_mw6m6c|    2|\n",
            "|        sucks|      negative|n_Lv_mw6m6c|    2|\n",
            "|         fail|      negative|n_Lv_mw6m6c|    2|\n",
            "|      dislike|      negative|n_Lv_mw6m6c|    1|\n",
            "|     negative|      negative|n_Lv_mw6m6c|    1|\n",
            "|     horrible|      negative|n_Lv_mw6m6c|    1|\n",
            "|     pathetic|      negative|n_Lv_mw6m6c|    1|\n",
            "|  frustrating|      negative|n_Lv_mw6m6c|    0|\n",
            "|disappointing|      negative|n_Lv_mw6m6c|    0|\n",
            "|           or|       neutral|n_Lv_mw6m6c| 1627|\n",
            "|           so|       neutral|n_Lv_mw6m6c| 1053|\n",
            "|          and|       neutral|n_Lv_mw6m6c|  915|\n",
            "|         just|       neutral|n_Lv_mw6m6c|  432|\n",
            "|          but|       neutral|n_Lv_mw6m6c|  295|\n",
            "|         also|       neutral|n_Lv_mw6m6c|  118|\n",
            "|         then|       neutral|n_Lv_mw6m6c|  102|\n",
            "|        maybe|       neutral|n_Lv_mw6m6c|   48|\n",
            "|        a bit|       neutral|n_Lv_mw6m6c|   19|\n",
            "|          yet|       neutral|n_Lv_mw6m6c|   17|\n",
            "|       either|       neutral|n_Lv_mw6m6c|   11|\n",
            "|       indeed|       neutral|n_Lv_mw6m6c|    6|\n",
            "|    meanwhile|       neutral|n_Lv_mw6m6c|    6|\n",
            "|      perhaps|       neutral|n_Lv_mw6m6c|    3|\n",
            "|      whether|       neutral|n_Lv_mw6m6c|    3|\n",
            "|     somewhat|       neutral|n_Lv_mw6m6c|    2|\n",
            "|      however|       neutral|n_Lv_mw6m6c|    1|\n",
            "|      neither|       neutral|n_Lv_mw6m6c|    1|\n",
            "|   regardless|       neutral|n_Lv_mw6m6c|    0|\n",
            "|         like|      positive|n_Lv_mw6m6c|  351|\n",
            "|         love|      positive|n_Lv_mw6m6c|  197|\n",
            "|         good|      positive|n_Lv_mw6m6c|  151|\n",
            "|        great|      positive|n_Lv_mw6m6c|   72|\n",
            "|         nice|      positive|n_Lv_mw6m6c|   50|\n",
            "|         best|      positive|n_Lv_mw6m6c|   47|\n",
            "|        enjoy|      positive|n_Lv_mw6m6c|   41|\n",
            "|        happy|      positive|n_Lv_mw6m6c|   30|\n",
            "|        super|      positive|n_Lv_mw6m6c|   26|\n",
            "|         cool|      positive|n_Lv_mw6m6c|   24|\n",
            "|      amazing|      positive|n_Lv_mw6m6c|   19|\n",
            "|      awesome|      positive|n_Lv_mw6m6c|   12|\n",
            "|      perfect|      positive|n_Lv_mw6m6c|   12|\n",
            "|    beautiful|      positive|n_Lv_mw6m6c|    8|\n",
            "|    excellent|      positive|n_Lv_mw6m6c|    2|\n",
            "|    fantastic|      positive|n_Lv_mw6m6c|    2|\n",
            "|    wonderful|      positive|n_Lv_mw6m6c|    2|\n",
            "|     positive|      positive|n_Lv_mw6m6c|    1|\n",
            "|    brilliant|      positive|n_Lv_mw6m6c|    1|\n",
            "|   delightful|      positive|n_Lv_mw6m6c|    0|\n",
            "+-------------+--------------+-----------+-----+\n",
            "\n",
            "Row count: 57\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ar5AEhYdWyt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ed0b28b",
        "outputId": "b245be56-85e8-4a7b-f9f8-80e8bacaae89"
      },
      "source": [
        "# calculate total counts for a video's positive/negative/neutral words\n",
        "total_sentiment_counts = final_keyword_analysis_df.groupBy(\"video_id\", \"keyword_family\").agg(\n",
        "    F.sum(\"count\").alias(\"total_category_count\")\n",
        ").orderBy(\"video_id\", \"keyword_family\")\n",
        "\n",
        "print(\"\\nTotal counts of words by sentiment category for video 'n_Lv_mw6m6c':\")\n",
        "total_sentiment_counts.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total counts of words by sentiment category for video 'n_Lv_mw6m6c':\n",
            "+-----------+--------------+--------------------+\n",
            "|   video_id|keyword_family|total_category_count|\n",
            "+-----------+--------------+--------------------+\n",
            "|n_Lv_mw6m6c|      negative|                 195|\n",
            "|n_Lv_mw6m6c|       neutral|                4659|\n",
            "|n_Lv_mw6m6c|      positive|                1048|\n",
            "+-----------+--------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59119e52",
        "outputId": "ff2a2361-94bc-42be-e0e3-d4f6271e66a3"
      },
      "source": [
        "# calculate the average number of occurrences of each keyword by category\n",
        "avg_sentiment_keyword_occurrence = final_keyword_analysis_df.groupBy(\"video_id\", \"keyword_family\").agg(\n",
        "    F.round(F.avg(\"count\"), 2).alias(\"avg_keyword_occurrence_in_category\")\n",
        ").orderBy(\"video_id\", \"keyword_family\")\n",
        "\n",
        "print(\"\\nAverage occurrence of keywords by sentiment category for video 'n_Lv_mw6m6c':\")\n",
        "avg_sentiment_keyword_occurrence.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average occurrence of keywords by sentiment category for video 'n_Lv_mw6m6c':\n",
            "+-----------+--------------+----------------------------------+\n",
            "|   video_id|keyword_family|avg_keyword_occurrence_in_category|\n",
            "+-----------+--------------+----------------------------------+\n",
            "|n_Lv_mw6m6c|      negative|                             10.83|\n",
            "|n_Lv_mw6m6c|       neutral|                            245.21|\n",
            "|n_Lv_mw6m6c|      positive|                              52.4|\n",
            "+-----------+--------------+----------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#temporal data: show the total comments per video and average number of comments per video each month\n",
        "\n",
        "from pyspark.sql.functions import month, countDistinct\n",
        "\n",
        "monthly_stats = cleaned_df.withColumn(\"month\", month(\"published_at\")) \\\n",
        "    .groupBy(\"month\") \\\n",
        "    .agg(\n",
        "        F.count(\"comment_id\").alias(\"tmonth_total\"),\n",
        "        F.countDistinct(\"video_id\").alias(\"total_videos_in_month\")\n",
        "    )\n",
        "\n",
        "monthly_stats = monthly_stats.withColumn(\"tavg_per_video\", F.round(F.col(\"tmonth_total\") / F.col(\"total_videos_in_month\"), 2)) \\\n",
        "    .filter(F.col(\"month\").isNotNull())\n",
        "\n",
        "monthly_stats = monthly_stats.orderBy(\"tmonth_total\")\n",
        "\n",
        "monthly_stats.orderBy(\"month\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4KQjMMWUlIs",
        "outputId": "bc151f1b-05aa-4c9f-c026-fa05980f70f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------------+---------------------+--------------+\n",
            "|month|tmonth_total|total_videos_in_month|tavg_per_video|\n",
            "+-----+------------+---------------------+--------------+\n",
            "|    4|        1206|                    5|         241.2|\n",
            "|    5|        8903|                   10|         890.3|\n",
            "|    6|       24786|                   14|       1770.43|\n",
            "|    7|       13217|                   22|        600.77|\n",
            "|    8|       51950|                   35|       1484.29|\n",
            "|    9|       87111|                  102|        854.03|\n",
            "+-----+------------+---------------------+--------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}